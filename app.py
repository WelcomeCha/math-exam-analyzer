import streamlit as st
import google.generativeai as genai
from google.generativeai import caching
import os
import tempfile
import time
import markdown
import pypdf
import datetime
import json
import re

# 1. ì„¤ì • ë° ìŠ¤íƒ€ì¼ë§
st.set_page_config(page_title="ìˆ˜í•™ ê¸°ì¶œ ë¶„ì„ê¸° (Auto Sort)", layout="wide")
st.markdown("""
    <style>
    div[data-testid="stMarkdownContainer"] p, td, th { 
        font-family: 'Malgun Gothic', sans-serif !important; 
        font-size: 15px !important;
        line-height: 1.6 !important;
    }
    table {
        width: 100% !important;
        table-layout: fixed !important;
        border-collapse: collapse !important;
    }
    th, td {
        border: 1px solid #ddd !important;
        padding: 12px !important;
        vertical-align: top !important;
        word-wrap: break-word !important;
    }
    th:nth-child(1) { width: 8% !important; }
    th:nth-child(2) { width: 30% !important; }
    th:nth-child(3) { width: 31% !important; }
    th:nth-child(4) { width: 31% !important; }
    th { background-color: #007bff !important; color: white !important; text-align: center !important; }
    
    .token-info {
        font-size: 12px;
        color: #666;
        background-color: #f8f9fa;
        padding: 5px 10px;
        border-radius: 5px;
        border: 1px solid #eee;
        margin-bottom: 10px;
    }
    .token-cached { color: #2e7d32; font-weight: bold; }
    .token-new { color: #d32f2f; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ’¯ ìˆ˜í•™ ê¸°ì¶œ ë¶„ì„ê¸° (ë²ˆí˜¸ ìë™ ì •ë ¬)")

# 2. ì„¸ì…˜ ì´ˆê¸°í™”
if 'analysis_history' not in st.session_state:
    st.session_state['analysis_history'] = []
if 'question_list' not in st.session_state:
    st.session_state['question_list'] = [] 
if 'last_index' not in st.session_state:
    st.session_state['last_index'] = 0
if 'cache_name' not in st.session_state:
    st.session_state['cache_name'] = None

# 3. API í‚¤
with st.sidebar:
    st.header("ì„¤ì •")
    api_key = st.text_input("Google API Key", type="password")
    st.divider()
    st.info("ğŸ”’ **ëª¨ë¸:** gemini-2.5-pro")
    st.info("ğŸ”¢ **ì •ë ¬:** ë¬¸í•­ ë²ˆí˜¸ë¥¼ ì¸ì‹í•˜ì—¬ ìë™ìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ(1->2->ì„œë‹µ1) ì •ë ¬í•©ë‹ˆë‹¤.")
    
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
        genai.configure(api_key=api_key)

# 4. íŒŒì¼ ì—…ë¡œë“œ
col1, col2 = st.columns(2)
with col1:
    exam_file = st.file_uploader("ê¸°ì¶œ PDF", type=['pdf'])
with col2:
    textbook_files = st.file_uploader("ë¶€êµì¬ PDF (ë‹¤ì¤‘)", type=['pdf'], accept_multiple_files=True)

# --- í•¨ìˆ˜ ì •ì˜ ---

def split_and_upload_pdf(uploaded_file, chunk_size_pages=30):
    pdf_reader = pypdf.PdfReader(uploaded_file)
    total_pages = len(pdf_reader.pages)
    
    if total_pages <= chunk_size_pages:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        return [genai.upload_file(tmp_path, mime_type="application/pdf")]

    status = st.empty()
    status.info(f"ğŸ”ª ë¶„í•  ì—…ë¡œë“œ ì¤‘... ({uploaded_file.name})")
    
    uploaded_chunks = []
    for start in range(0, total_pages, chunk_size_pages):
        end = min(start + chunk_size_pages, total_pages)
        pdf_writer = pypdf.PdfWriter()
        for p in range(start, end):
            pdf_writer.add_page(pdf_reader.pages[p])
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_part_{start}.pdf") as tmp:
            pdf_writer.write(tmp)
            tmp_path = tmp.name
        try:
            uploaded_chunks.append(genai.upload_file(tmp_path, mime_type="application/pdf"))
        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    status.empty()
    return uploaded_chunks

def wait_for_files_active(files):
    status = st.empty()
    for f in files:
        file_obj = genai.get_file(f.name)
        while file_obj.state.name == "PROCESSING":
            status.info(f"â³ ì„œë²„ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘... {file_obj.display_name}")
            time.sleep(2)
            file_obj = genai.get_file(f.name)
        if file_obj.state.name != "ACTIVE":
            st.error("íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()
    status.empty()

# ğŸ”¥ [í•µì‹¬ ê¸°ëŠ¥] ë¬¸í•­ ë¦¬ìŠ¤íŠ¸ ê°•ì œ ì •ë ¬ í•¨ìˆ˜
def sort_question_list(q_list):
    def sort_key(x):
        # 1. ìˆ«ìë§Œ ìˆëŠ” ê²½ìš° (ê°ê´€ì‹) -> ìš°ì„ ìˆœìœ„ 0
        if str(x).isdigit():
            return (0, int(x))
        
        # 2. í…ìŠ¤íŠ¸ê°€ ì„ì¸ ê²½ìš° (ì„œë‹µí˜• ë“±) -> ìš°ì„ ìˆœìœ„ 1
        # ì •ê·œì‹ìœ¼ë¡œ ìˆ«ìë§Œ ì¶”ì¶œí•´ì„œ ì„œë¸Œ ì •ë ¬
        num_match = re.search(r'\d+', str(x))
        num = int(num_match.group()) if num_match else 999
        return (1, num)
    
    return sorted(q_list, key=sort_key)

def scan_exam_structure(model):
    """ì‹œí—˜ì§€ ë¬¸í•­ ë²ˆí˜¸ ìë™ íŒŒì•…"""
    prompt = """
    ì´ ì‹œí—˜ì§€ PDF ì „ì²´ë¥¼ í›‘ì–´ë³´ê³  **ëª¨ë“  ë¬¸ì œ ë²ˆí˜¸**ë¥¼ ë¹ ì§ì—†ì´ ë¦¬ìŠ¤íŠ¸ë¡œ ë½‘ì•„ë¼.
    
    **[ê·œì¹™]**
    1. ê°ê´€ì‹ì€ ìˆ«ìë§Œ (ì˜ˆ: "1", "2", ... "18")
    2. ì„œìˆ í˜•ì€ í‘œê¸° ê·¸ëŒ€ë¡œ (ì˜ˆ: "[ì„œë‹µí˜• 1]", "ì£¼ê´€ì‹ 1")
    **[ì¶œë ¥]** Python List JSON í˜•ì‹ë§Œ (ì˜ˆ: ["1", "2", "[ì„œë‹µí˜• 1]"])
    """
    try:
        response = model.generate_content(prompt)
        text = response.text
        json_match = re.search(r'\[.*\]', text, re.DOTALL)
        if json_match:
            raw_list = json.loads(json_match.group())
            # ğŸ”¥ ì—¬ê¸°ì„œ ê°•ì œ ì •ë ¬ ì‹¤í–‰
            return sort_question_list(raw_list)
        else:
            return []
    except:
        return []

def create_html(text_list):
    full_text = "\n\n".join(text_list)
    html_body = markdown.markdown(full_text, extensions=['tables'])
    return f"""
    <html><head><meta charset="utf-8">
    <script>MathJax={{tex:{{inlineMath:[['$','$']],displayMath:[['$$','$$']]}},svg:{{fontCache:'global'}} }};</script>
    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {{ font-family: 'Malgun Gothic', sans-serif; padding: 40px; line-height: 1.6; max-width: 1400px; margin: 0 auto; }}
        table {{ border-collapse: collapse; width: 100%; table-layout: fixed; margin-bottom: 30px; }}
        th, td {{ border: 1px solid #ddd; padding: 15px; vertical-align: top; word-wrap: break-word; }}
        th {{ background: #007bff; color: white; text-align: center; }}
        th:nth-child(1) {{ width: 8%; }} th:nth-child(2) {{ width: 30%; }}
        th:nth-child(3) {{ width: 31%; }} th:nth-child(4) {{ width: 31%; }}
        tr:nth-child(even) {{ background: #f2f2f2; }}
    </style></head><body>{html_body}</body></html>
    """

# 5. ë©”ì¸ ë¡œì§
if exam_file and textbook_files and api_key:
    c1, c2 = st.columns(2)
    start_btn = c1.button("ğŸš€ êµ¬ì¡° íŒŒì•… & ë¶„ì„ ì‹œì‘")
    resume_btn = False
    
    if st.session_state['question_list'] and st.session_state['last_index'] < len(st.session_state['question_list']):
        resume_btn = c2.button("â¯ï¸ ì´ì–´í•˜ê¸°")

    if start_btn or resume_btn:
        try:
            status = st.empty()
            
            # 1. ìºì‹œ ìƒì„±
            if not st.session_state.get('cache_name') or start_btn:
                st.session_state['analysis_history'] = []
                st.session_state['question_list'] = []
                st.session_state['last_index'] = 0
                
                all_files = []
                exam_chunks = split_and_upload_pdf(exam_file)
                if exam_chunks: all_files.extend(exam_chunks)
                for tf in textbook_files:
                    tb_chunks = split_and_upload_pdf(tf)
                    if tb_chunks: all_files.extend(tb_chunks)
                
                if not all_files: st.stop()
                wait_for_files_active(all_files)
                
                status.info("ğŸ’¾ ìºì‹œ ìƒì„± ì¤‘...")
                cache = caching.CachedContent.create(
                    model='models/gemini-2.5-pro',
                    display_name='sorted_scan_analysis',
                    system_instruction="ë„ˆëŠ” ìˆ˜í•™ ë¶„ì„ê°€ë‹¤. ë°˜ë§(í•´ë¼ì²´), LaTeX($) í•„ìˆ˜, í‘œ ì–‘ì‹ ì¤€ìˆ˜.",
                    contents=all_files,
                    ttl=datetime.timedelta(minutes=60)
                )
                st.session_state['cache_name'] = cache.name
            
            model = genai.GenerativeModel.from_cached_content(cached_content=caching.CachedContent.get(st.session_state['cache_name']))
            
            # 2. êµ¬ì¡° íŒŒì•… ë° ì •ë ¬
            if not st.session_state['question_list']:
                status.info("ğŸ” ì‹œí—˜ì§€ ìŠ¤ìº” ë° ë²ˆí˜¸ ì •ë ¬ ì¤‘...")
                detected_questions = scan_exam_structure(model)
                if not detected_questions:
                    st.error("ë¬¸í•­ ì¸ì‹ ì‹¤íŒ¨")
                    st.stop()
                st.session_state['question_list'] = detected_questions
                
                # ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ ë³´ì—¬ì£¼ê¸°
                st.success(f"âœ… ì •ë ¬ëœ ë¬¸í•­ ë¦¬ìŠ¤íŠ¸: {', '.join(detected_questions)}")
                time.sleep(2)

            q_list = st.session_state['question_list']
            start_idx = st.session_state['last_index']
            p_bar = st.progress(start_idx / len(q_list))
            
            for i in range(start_idx, len(q_list)):
                q_label = q_list[i]
                display_label = q_label + "ë²ˆ" if q_label.isdigit() else q_label
                
                status.info(f"ğŸ”„ ë¶„ì„ ì¤‘... {display_label} (ìºì‹œ í™œìš© ì¤‘)")
                
                prompt = f"""
                ê¸°ì¶œë¬¸ì œ PDFì—ì„œ ì •í™•íˆ **'{q_label}'** ë¬¸í•­ì„ ì°¾ì•„ ë¶„ì„í•´ë¼.
                
                **[ì‘ì„± ê°€ì´ë“œ - ì—„ê²© ì¤€ìˆ˜]**
                1. **ì¶œì²˜ í‘œê¸°:** [ì›ë³¸] ì²« ì¤„ì€ ë°˜ë“œì‹œ **`[êµì¬ëª…] p.00 00ë²ˆ`** ì–‘ì‹.
                2. **ë§íˆ¬:** ë¬´ì¡°ê±´ ë°˜ë§(í•´ë¼ì²´).
                3. **ìˆ˜ì‹:** `$ ... $` (LaTeX) í•„ìˆ˜.
                4. **ìƒì„¸ ë¶„ì„:** 'â–¶ ë³€í˜• í¬ì¸íŠ¸', 'â–¶ ì¶œì œ ì˜ë„'ë§Œ í•µì‹¬ ìš”ì•½. (í’€ì´ ê³¼ì • X)
                
                | ë¬¸í•­ | ê¸°ì¶œ ìš”ì•½ | ë¶€êµì¬ ìœ ì‚¬ ë¬¸í•­ | ìƒì„¸ ë³€í˜• ë¶„ì„ |
                | :--- | :--- | :--- | :--- |
                | {display_label} | **[ì›ë³¸]**<br>(LaTeX)<br><br>**[ìš”ì•½]** | **[ì›ë³¸]**<br>[êµì¬ëª…] p.xx xxë²ˆ<br>(LaTeX)<br><br>**[ìš”ì•½]** | **â–¶ ë³€í˜• í¬ì¸íŠ¸**<br>â€¢ ë‚´ìš©<br><br>**â–¶ ì¶œì œ ì˜ë„**<br>â€¢ ë‚´ìš© |
                """
                
                success = False
                for attempt in range(3):
                    try:
                        resp = model.generate_content(prompt)
                        if resp.parts:
                            txt = resp.text
                            usage = resp.usage_metadata
                            total = usage.prompt_token_count
                            
                            token_info = f"<div class='token-info'>ğŸ“Š í† í°: ì „ì²´ {total:,} (ìºì‹œë¨) + ì‹ ê·œ ì•½ 300</div>"
                            st.markdown(token_info, unsafe_allow_html=True)
                            
                            st.session_state['analysis_history'].append(txt)
                            st.markdown(txt, unsafe_allow_html=True)
                            success = True
                            break
                    except:
                        time.sleep(1)
                
                if not success:
                    st.warning(f"âš ï¸ {display_label} ì‹¤íŒ¨ (ê±´ë„ˆëœ€)")
                
                st.session_state['last_index'] = i + 1
                p_bar.progress((i + 1) / len(q_list))
            
            status.success("ğŸ‰ ì •ë ¬ ë¶„ì„ ì™„ë£Œ!")
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

    if st.session_state['analysis_history']:
        st.divider()
        html = create_html(st.session_state['analysis_history'])
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", html, "ë¶„ì„ê²°ê³¼.html")
