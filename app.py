import streamlit as st
import google.generativeai as genai
from google.generativeai import caching
import os
import tempfile
import time
import markdown
import pypdf
import datetime
import json
import re

# 1. ì„¤ì • ë° ìŠ¤íƒ€ì¼ë§
st.set_page_config(page_title="ìˆ˜í•™ ê¸°ì¶œ ë¶„ì„ê¸° (Final Sequential)", layout="wide")
st.markdown("""
    <style>
    div[data-testid="stMarkdownContainer"] p, td, th { 
        font-family: 'Malgun Gothic', sans-serif !important; 
        font-size: 15px !important;
        line-height: 1.6 !important;
    }
    table {
        width: 100% !important;
        table-layout: fixed !important;
        border-collapse: collapse !important;
    }
    th, td {
        border: 1px solid #ddd !important;
        padding: 12px !important;
        vertical-align: top !important;
        word-wrap: break-word !important;
    }
    th:nth-child(1) { width: 8% !important; }
    th:nth-child(2) { width: 30% !important; }
    th:nth-child(3) { width: 31% !important; }
    th:nth-child(4) { width: 31% !important; }
    th { background-color: #007bff !important; color: white !important; text-align: center !important; }
    
    .token-info {
        font-size: 12px;
        color: #666;
        background-color: #f8f9fa;
        padding: 5px 10px;
        border-radius: 5px;
        border: 1px solid #eee;
        margin-bottom: 10px;
    }
    .token-cached { color: #2e7d32; font-weight: bold; }
    .token-new { color: #d32f2f; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ’¯ ìˆ˜í•™ ê¸°ì¶œ ë¶„ì„ê¸° (ìˆœì°¨ ê°•ì œ ëª¨ë“œ)")

# 2. ì„¸ì…˜ ì´ˆê¸°í™”
if 'analysis_history' not in st.session_state:
    st.session_state['analysis_history'] = []
# ê°•ì œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì €ì¥í•  ì„¸ì…˜
if 'target_list' not in st.session_state:
    st.session_state['target_list'] = [] 
if 'last_index' not in st.session_state:
    st.session_state['last_index'] = 0
if 'cache_name' not in st.session_state:
    st.session_state['cache_name'] = None

# 3. API í‚¤
with st.sidebar:
    st.header("ì„¤ì •")
    api_key = st.text_input("Google API Key", type="password")
    st.divider()
    st.info("ğŸ”’ **ëª¨ë¸:** gemini-2.5-pro")
    st.info("ğŸ”¢ **ìˆœì„œ ê°•ì œ:** 1ë²ˆë¶€í„° 25ë²ˆ, ì„œë‹µí˜• 1ë²ˆë¶€í„° 6ë²ˆê¹Œì§€ ìˆœì„œëŒ€ë¡œ ê°•ì œ íƒìƒ‰í•©ë‹ˆë‹¤. (ëˆ„ë½/ë’¤ì„ì„ ë°©ì§€)")
    
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
        genai.configure(api_key=api_key)

# 4. íŒŒì¼ ì—…ë¡œë“œ
col1, col2 = st.columns(2)
with col1:
    exam_file = st.file_uploader("ê¸°ì¶œ PDF", type=['pdf'])
with col2:
    textbook_files = st.file_uploader("ë¶€êµì¬ PDF (ë‹¤ì¤‘)", type=['pdf'], accept_multiple_files=True)

# --- í•¨ìˆ˜ ì •ì˜ ---

def split_and_upload_pdf(uploaded_file, chunk_size_pages=30):
    pdf_reader = pypdf.PdfReader(uploaded_file)
    total_pages = len(pdf_reader.pages)
    
    if total_pages <= chunk_size_pages:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        return [genai.upload_file(tmp_path, mime_type="application/pdf")]

    status = st.empty()
    status.info(f"ğŸ”ª ë¶„í•  ì—…ë¡œë“œ ì¤‘... ({uploaded_file.name})")
    
    uploaded_chunks = []
    for start in range(0, total_pages, chunk_size_pages):
        end = min(start + chunk_size_pages, total_pages)
        pdf_writer = pypdf.PdfWriter()
        for p in range(start, end):
            pdf_writer.add_page(pdf_reader.pages[p])
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_part_{start}.pdf") as tmp:
            pdf_writer.write(tmp)
            tmp_path = tmp.name
        try:
            uploaded_chunks.append(genai.upload_file(tmp_path, mime_type="application/pdf"))
        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
            return None
    status.empty()
    return uploaded_chunks

def wait_for_files_active(files):
    status = st.empty()
    for f in files:
        file_obj = genai.get_file(f.name)
        while file_obj.state.name == "PROCESSING":
            status.info(f"â³ ì„œë²„ ì²˜ë¦¬ ëŒ€ê¸° ì¤‘... {file_obj.display_name}")
            time.sleep(2)
            file_obj = genai.get_file(f.name)
        if file_obj.state.name != "ACTIVE":
            st.error("íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            st.stop()
    status.empty()

def create_html(text_list):
    full_text = "\n\n".join(text_list)
    html_body = markdown.markdown(full_text, extensions=['tables'])
    return f"""
    <html><head><meta charset="utf-8">
    <script>MathJax={{tex:{{inlineMath:[['$','$']],displayMath:[['$$','$$']]}},svg:{{fontCache:'global'}} }};</script>
    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {{ font-family: 'Malgun Gothic', sans-serif; padding: 40px; line-height: 1.6; max-width: 1400px; margin: 0 auto; }}
        table {{ border-collapse: collapse; width: 100%; table-layout: fixed; margin-bottom: 30px; }}
        th, td {{ border: 1px solid #ddd; padding: 15px; vertical-align: top; word-wrap: break-word; }}
        th {{ background: #007bff; color: white; text-align: center; }}
        th:nth-child(1) {{ width: 8%; }} th:nth-child(2) {{ width: 30%; }}
        th:nth-child(3) {{ width: 31%; }} th:nth-child(4) {{ width: 31%; }}
        tr:nth-child(even) {{ background: #f2f2f2; }}
    </style></head><body>{html_body}</body></html>
    """

# 5. ë©”ì¸ ë¡œì§
if exam_file and textbook_files and api_key:
    c1, c2 = st.columns(2)
    start_btn = c1.button("ğŸš€ ë¶„ì„ ì‹œì‘ (ìˆœì°¨ ê°•ì œ)")
    resume_btn = False
    
    # ì´ì–´í•˜ê¸° ë²„íŠ¼ í™œì„±í™” ì¡°ê±´
    if st.session_state['target_list'] and st.session_state['last_index'] < len(st.session_state['target_list']):
        resume_btn = c2.button("â¯ï¸ ì´ì–´í•˜ê¸°")

    if start_btn or resume_btn:
        try:
            status = st.empty()
            
            # 1. ìºì‹œ ìƒì„± ë° ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            if not st.session_state.get('cache_name') or start_btn:
                st.session_state['analysis_history'] = []
                st.session_state['last_index'] = 0
                
                # ğŸ”¥ [í•µì‹¬] ë¶„ì„í•  ë¦¬ìŠ¤íŠ¸ë¥¼ ì½”ë“œë¡œ ê°•ì œ ìƒì„± (AIì—ê²Œ ë§¡ê¸°ì§€ ì•ŠìŒ)
                # ê°ê´€ì‹ 1~25, ì„œë‹µí˜• 1~6 (ì¶©ë¶„íˆ ë„‰ë„‰í•˜ê²Œ ì¡ìŒ)
                forced_list = [f"{i}" for i in range(1, 26)] + \
                              [f"[ì„œë‹µí˜• {i}]" for i in range(1, 7)]
                st.session_state['target_list'] = forced_list
                
                all_files = []
                exam_chunks = split_and_upload_pdf(exam_file)
                if exam_chunks: all_files.extend(exam_chunks)
                for tf in textbook_files:
                    tb_chunks = split_and_upload_pdf(tf)
                    if tb_chunks: all_files.extend(tb_chunks)
                
                if not all_files: st.stop()
                wait_for_files_active(all_files)
                
                status.info("ğŸ’¾ ìºì‹œ ìƒì„± ì¤‘...")
                cache = caching.CachedContent.create(
                    model='models/gemini-2.5-pro',
                    display_name='sequential_analysis_v4',
                    system_instruction="ë„ˆëŠ” ìˆ˜í•™ ë¶„ì„ê°€ë‹¤. ë°˜ë§(í•´ë¼ì²´), LaTeX($) í•„ìˆ˜, í‘œ ì–‘ì‹ ì¤€ìˆ˜.",
                    contents=all_files,
                    ttl=datetime.timedelta(minutes=60)
                )
                st.session_state['cache_name'] = cache.name
            
            model = genai.GenerativeModel.from_cached_content(cached_content=caching.CachedContent.get(st.session_state['cache_name']))
            
            q_list = st.session_state['target_list']
            start_idx = st.session_state['last_index']
            p_bar = st.progress(start_idx / len(q_list))
            
            # 2. ìˆœì°¨ ë¶„ì„ ë£¨í”„
            for i in range(start_idx, len(q_list)):
                q_label = q_list[i]
                
                # í™”ë©´ í‘œì‹œìš© ë¼ë²¨ (ìˆ«ìë©´ 'ë²ˆ' ë¶™ì´ê¸°)
                display_label = q_label + "ë²ˆ" if q_label.isdigit() else q_label
                
                status.info(f"ğŸ”„ í™•ì¸ ì¤‘... {display_label}")
                
                prompt = f"""
                ê¸°ì¶œë¬¸ì œ PDFì—ì„œ **'{display_label}'** ë¬¸ì œ(ë˜ëŠ” **'{q_label}'** í‘œê¸°)ê°€ ìˆëŠ”ì§€ ì°¾ì•„ë¼.
                
                **[ì£¼ì˜]**
                - ì„œë‹µí˜•ì˜ ê²½ìš° '[ì„œë‹µí˜• 1]', 'ì„œìˆ í˜• 1ë²ˆ', 'ë‹¨ë‹µí˜• 1' ë“± ë‹¤ì–‘í•œ í‘œê¸°ë¥¼ ëª¨ë‘ í™•ì¸í•´ë¼.
                - **í•´ë‹¹ ë²ˆí˜¸ì˜ ë¬¸ì œê°€ PDFì— ì•„ì˜ˆ ì—†ë‹¤ë©´, ê³ ë¯¼í•˜ì§€ ë§ê³  ì¦‰ì‹œ "SKIP" ì´ë¼ê³ ë§Œ ì¶œë ¥í•´ë¼.**
                
                **[ìˆìœ¼ë©´ ë¶„ì„ ì‘ì„±]**
                1. **ì¶œì²˜ í‘œê¸°:** [ì›ë³¸] ì²« ì¤„ì€ ë°˜ë“œì‹œ **`[êµì¬ëª…] p.00 00ë²ˆ`** ì–‘ì‹.
                2. **ë§íˆ¬:** ë¬´ì¡°ê±´ ë°˜ë§(í•´ë¼ì²´).
                3. **ìˆ˜ì‹:** `$ ... $` (LaTeX) í•„ìˆ˜.
                4. **ìƒì„¸ ë¶„ì„:** 'â–¶ ë³€í˜• í¬ì¸íŠ¸', 'â–¶ ì¶œì œ ì˜ë„'ë§Œ í•µì‹¬ ìš”ì•½. (í’€ì´ ê³¼ì • X)
                
                | ë¬¸í•­ | ê¸°ì¶œ ìš”ì•½ | ë¶€êµì¬ ìœ ì‚¬ ë¬¸í•­ | ìƒì„¸ ë³€í˜• ë¶„ì„ |
                | :--- | :--- | :--- | :--- |
                | {display_label} | **[ì›ë³¸]**<br>(LaTeX)<br><br>**[ìš”ì•½]** | **[ì›ë³¸]**<br>[êµì¬ëª…] p.xx xxë²ˆ<br>(LaTeX)<br><br>**[ìš”ì•½]** | **â–¶ ë³€í˜• í¬ì¸íŠ¸**<br>â€¢ ë‚´ìš©<br><br>**â–¶ ì¶œì œ ì˜ë„**<br>â€¢ ë‚´ìš© |
                """
                
                success = False
                for attempt in range(2): # ì¬ì‹œë„ íšŸìˆ˜ ì¤„ì„ (SKIP íŒë‹¨ ë¹ ë¥´ê²Œ)
                    try:
                        resp = model.generate_content(prompt)
                        if resp.parts:
                            txt = resp.text
                            # SKIPì´ë©´ ì¡°ìš©íˆ ë„˜ì–´ê°€ê¸°
                            if "SKIP" in txt:
                                success = True # ì˜ë„ëœ SKIPì´ë¯€ë¡œ ì„±ê³µ ì²˜ë¦¬
                                break
                            
                            # SKIPì´ ì•„ë‹ˆë©´ ê²°ê³¼ ì €ì¥
                            usage = resp.usage_metadata
                            total = usage.prompt_token_count
                            token_info = f"<div class='token-info'>ğŸ“Š {display_label}: ë¬¸ë§¥ {total:,} (ìºì‹œë¨) + ì‹ ê·œ ~300</div>"
                            st.markdown(token_info, unsafe_allow_html=True)
                            
                            st.session_state['analysis_history'].append(txt)
                            st.markdown(txt, unsafe_allow_html=True)
                            success = True
                            break
                    except:
                        time.sleep(1)
                
                # ì‹¤íŒ¨í–ˆê±°ë‚˜ SKIPì¸ ê²½ìš° ê·¸ëƒ¥ ë‹¤ìŒìœ¼ë¡œ (ì‚¬ìš©ìì—ê²Œ ê²½ê³  X, ê¹”ë”í•˜ê²Œ)
                st.session_state['last_index'] = i + 1
                p_bar.progress((i + 1) / len(q_list))
            
            status.success("ğŸ‰ ìˆœì°¨ ë¶„ì„ ì™„ë£Œ!")
            
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

    if st.session_state['analysis_history']:
        st.divider()
        html = create_html(st.session_state['analysis_history'])
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", html, "ë¶„ì„ê²°ê³¼.html")
