import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import os
import tempfile
import time
import markdown
import pypdf
from dotenv import load_dotenv

# 1. ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ìˆ˜í•™ ê¸°ì¶œ ë¶„ì„ê¸° (Ultimate)", layout="wide")

st.markdown("""
    <style>
    div[data-testid="stMarkdownContainer"] p, 
    div[data-testid="stMarkdownContainer"] li, 
    div[data-testid="stMarkdownContainer"] td {
        font-size: 15px !important;
        line-height: 1.7 !important;
        font-family: 'Malgun Gothic', sans-serif !important;
    }
    thead tr th {
        background-color: #f0f2f6 !important;
        font-weight: bold !important;
        font-size: 16px !important;
        text-align: center !important;
        white-space: nowrap;
    }
    td { vertical-align: top !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ’¯ ê³ ë“±í•™êµ ìˆ˜í•™ ê¸°ì¶œ vs ë¶€êµì¬ ë¶„ì„ê¸°")

# 2. API í‚¤ ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì •")
    api_key = st.text_input("Google API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    st.divider()
    st.info("ğŸ”’ **ëª¨ë¸:** Gemini 2.5 Pro")
    st.info("ğŸ›¡ï¸ **ì €ì‘ê¶Œ í•„í„° ìš°íšŒ:** ì›ë¬¸ ë³µì‚¬ ëŒ€ì‹  'ì •ë°€ ë³µì›' ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ëŠê¹€ì„ ë°©ì§€í•©ë‹ˆë‹¤.")
    
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
        genai.configure(api_key=api_key)
        st.success("API í‚¤ í™•ì¸ ì™„ë£Œ!")
    else:
        st.warning("API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")

# 3. íŒŒì¼ ì—…ë¡œë“œ
col1, col2 = st.columns(2)
with col1:
    st.subheader("ğŸ“„ í•™êµ ê¸°ì¶œë¬¸ì œ PDF")
    exam_file = st.file_uploader("ê¸°ì¶œë¬¸ì œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'], key="exam")

with col2:
    st.subheader("ğŸ“š ë¶€êµì¬ PDF (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)")
    textbook_files = st.file_uploader("ë¶€êµì¬ë“¤ì„ í•œêº¼ë²ˆì— ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'], key="textbooks", accept_multiple_files=True)


# --- PDF ìë™ ë¶„í•  ë° ì—…ë¡œë“œ í•¨ìˆ˜ ---
def split_and_upload_pdf(uploaded_file, file_label, chunk_size_pages=30):
    pdf_reader = pypdf.PdfReader(uploaded_file)
    total_pages = len(pdf_reader.pages)
    
    if total_pages <= chunk_size_pages:
        return [upload_single_file(uploaded_file)]

    status_text = st.empty()
    progress_bar = st.progress(0)
    status_text.info(f"ğŸ“– '{file_label}' íŒŒì¼ì´ í½ë‹ˆë‹¤({total_pages}ìª½). ë¶„í•  ì—…ë¡œë“œ ì¤‘...")
    
    uploaded_chunks = []
    
    for start_page in range(0, total_pages, chunk_size_pages):
        end_page = min(start_page + chunk_size_pages, total_pages)
        
        pdf_writer = pypdf.PdfWriter()
        for page_num in range(start_page, end_page):
            pdf_writer.add_page(pdf_reader.pages[page_num])
            
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_part_{start_page}.pdf") as tmp:
            pdf_writer.write(tmp)
            tmp_path = tmp.name
            
        try:
            file_ref = genai.upload_file(tmp_path, mime_type="application/pdf")
            uploaded_chunks.append(file_ref)
            progress = min((start_page + chunk_size_pages) / total_pages, 1.0)
            progress_bar.progress(progress)
        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
            
    status_text.success(f"âœ… '{file_label}' ì—…ë¡œë“œ ì™„ë£Œ!")
    time.sleep(0.5)
    status_text.empty()
    progress_bar.empty()
    return uploaded_chunks

def upload_single_file(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.getvalue())
        tmp_path = tmp.name
    file_ref = genai.upload_file(tmp_path, mime_type="application/pdf")
    return file_ref

def wait_for_files_active(file_list):
    st.info("ğŸ“š AIê°€ ëª¨ë“  ìë£Œë¥¼ í•™ìŠµí•˜ê³  ìˆìŠµë‹ˆë‹¤... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)")
    my_bar = st.progress(0)
    for i, file_obj in enumerate(file_list):
        current_file = genai.get_file(file_obj.name)
        while current_file.state.name == "PROCESSING":
            time.sleep(2)
            current_file = genai.get_file(file_obj.name)
        if current_file.state.name == "FAILED":
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {current_file.uri}")
            st.stop()
        my_bar.progress((i + 1) / len(file_list))
    st.success("âœ… ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")

# HTML ë³€í™˜ í•¨ìˆ˜
def create_html_download(markdown_text):
    html_content = markdown.markdown(markdown_text, extensions=['tables'])
    styled_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <script>
        MathJax = {{ tex: {{ inlineMath: [['$', '$'], ['\\\\(', '\\\\)']], displayMath: [['$$', '$$'], ['\\\\[', '\\\\]']] }}, svg: {{ fontCache: 'global' }} }};
        </script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <style>
            body {{ font-family: 'Malgun Gothic', sans-serif; line-height: 1.6; padding: 40px; max-width: 1200px; margin: 0 auto; }}
            table {{ border-collapse: collapse; width: 100%; margin-bottom: 30px; }}
            th, td {{ border: 1px solid #ddd; padding: 15px; text-align: left; vertical-align: top; }}
            th {{ background-color: #007bff; color: white; text-align: center; white-space: nowrap; }}
            tr:nth-child(even) {{ background-color: #f2f2f2; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“Š ìˆ˜í•™ ê¸°ì¶œ vs ë¶€êµì¬ 1:1 ì •ë°€ ë¶„ì„ ê²°ê³¼</h1>
        {html_content}
    </body>
    </html>
    """
    return styled_html

# 4. ë¶„ì„ ë¡œì§
if exam_file and textbook_files and api_key:
    if 'full_analysis_result' not in st.session_state:
        st.session_state['full_analysis_result'] = ""

    if st.button("1ë¬¸í•­ì”© ì •ë°€ ë¶„ì„ ì‹œì‘ ğŸš€", use_container_width=True):
        st.session_state['full_analysis_result'] = ""
        
        try:
            # 1. íŒŒì¼ ì—…ë¡œë“œ ë° ì¤€ë¹„
            exam_ref = upload_single_file(exam_file)
            all_textbook_refs = []
            
            for t_file in textbook_files:
                refs = split_and_upload_pdf(t_file, t_file.name, chunk_size_pages=30)
                if refs:
                    all_textbook_refs.extend(refs)
            
            if not all_textbook_refs:
                st.error("ë¶€êµì¬ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                st.stop()

            all_files_to_wait = [exam_ref] + all_textbook_refs
            wait_for_files_active(all_files_to_wait)

            # 2. ëª¨ë¸ ì„¤ì • (ì•ˆì „ì„± ìµœìš°ì„ )
            model = genai.GenerativeModel(
                "gemini-2.5-pro",
                generation_config={"temperature": 0.0, "max_output_tokens": 8192},
                safety_settings={
                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                }
            )

            # ë¬¸í•­ ë¦¬ìŠ¤íŠ¸ ìƒì„±
            batches = []
            for i in range(1, 26): batches.append((f"{i}ë²ˆ", f"ê¸°ì¶œë¬¸ì œì˜ {i}ë²ˆ ë¬¸í•­ë§Œ"))
            for i in range(1, 7): batches.append((f"ì„œë‹µí˜• {i}ë²ˆ", f"ê¸°ì¶œë¬¸ì œì˜ ì„œë‹µí˜•(ë˜ëŠ” ì„œìˆ í˜•) {i}ë²ˆ ë¬¸í•­ë§Œ"))

            full_accumulated_text = ""
            status_text = st.empty()
            total_progress = st.progress(0)

            for i, (title, range_desc) in enumerate(batches):
                status_text.info(f"ğŸ”„ {title} ë¶„ì„ ì¤‘... ({i+1}/{len(batches)})")
                
                # --- ğŸ”¥ [í•µì‹¬ 1] ì €ì‘ê¶Œ í•„í„° ìš°íšŒ í”„ë¡¬í”„íŠ¸ ---
                prompt = f"""
                ë‹¹ì‹ ì€ ìˆ˜í•™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ì²« ë²ˆì§¸ PDFëŠ” 'í•™êµ ê¸°ì¶œë¬¸ì œ'ì´ê³ , ë‚˜ë¨¸ì§€ëŠ” 'ë¶€êµì¬'ì…ë‹ˆë‹¤.
                
                ê¸°ì¶œë¬¸ì œì—ì„œ **ì˜¤ì§ [{range_desc}]** ì°¾ì•„ì„œ ë¶„ì„í•˜ì„¸ìš”.
                
                **[ì¶œë ¥ ì„œì‹ ê°€ì´ë“œë¼ì¸ - ì—„ê²© ì¤€ìˆ˜]**
                1. **ë¶€êµì¬ ë¬¸í•­ í‘œê¸°:** `p.í˜ì´ì§€ ë¬¸í•­ë²ˆí˜¸` (ì˜ˆ: p.80 285ë²ˆ)
                2. **ì›ë¬¸ ë³µì›:** 'ë³µì‚¬'í•˜ì§€ ë§ê³ , ë¬¸ì œì˜ ìˆ˜ì¹˜, ì¡°ê±´, ì§ˆë¬¸ì„ ì™„ë²½í•˜ê²Œ ì¬êµ¬ì„±í•˜ì—¬ **[ì›ë³¸]** íƒœê·¸ ì•„ë˜ì— ì ìœ¼ì„¸ìš”. (ê·¸ë¦¼ ë¬˜ì‚¬ëŠ” ìƒëµ)
                3. **ë§Œì•½ ë¬¸ì œê°€ ì—†ìœ¼ë©´:** "SKIP" ì´ë¼ê³ ë§Œ ì¶œë ¥.
                
                **[ì¶œë ¥ í…Œì´ë¸” ì–‘ì‹]**
                | ë¬¸í•­ | ê¸°ì¶œë¬¸ì œ ìš”ì•½ | ë¶€êµì¬ ìœ ì‚¬ ë¬¸í•­ | ìƒì„¸ ë³€í˜• ë¶„ì„ |
                | :--- | :--- | :--- | :--- |
                | {title} | **[ì›ë³¸]**<br>(ê¸°ì¶œ í…ìŠ¤íŠ¸)<br><br>**[ìš”ì•½]**<br>(ìš”ì•½) | **[ì›ë³¸]**<br>(êµì¬ëª…) p.00 000ë²ˆ<br>(ë¬¸ì œ ë‚´ìš© ìƒì„¸ ë³µì›)<br><br>**[ìš”ì•½]**<br>(ìš”ì•½) | **â–¶ ë³€í˜• í¬ì¸íŠ¸**<br>â€¢ **í‚¤ì›Œë“œ**: ì„¤ëª…<br>â€¢ **í‚¤ì›Œë“œ**: ì„¤ëª…<br><br>**â–¶ ì¶œì œ ì˜ë„**<br>(í‰ê°€ ëª©í‘œ) |
                """
                
                request_content = [prompt, exam_ref] + all_textbook_refs
                
                # --- ğŸ”¥ [í•µì‹¬ 2] ì¬ì‹œë„(Retry) ë¡œì§ & ìŠ¤íŠ¸ë¦¬ë° ì ìš© ---
                max_retries = 2
                success = False
                
                for attempt in range(max_retries):
                    try:
                        chunk_text = ""
                        # ìŠ¤íŠ¸ë¦¬ë°ì„ ì¼œì•¼ ì—°ê²° ìœ ì§€ì— ìœ ë¦¬í•¨
                        stream = model.generate_content(request_content, stream=True)
                        
                        for chunk in stream:
                            if chunk.text:
                                chunk_text += chunk.text
                        
                        # ë‚´ìš©ì´ ìˆê³  SKIPì´ ì•„ë‹ˆë©´ ì„±ê³µ
                        if chunk_text and "SKIP" not in chunk_text:
                            if i == 0: st.markdown(f"### ğŸ“‹ ë¶„ì„ ê²°ê³¼")
                            st.markdown(chunk_text, unsafe_allow_html=True)
                            full_accumulated_text += chunk_text + "\n\n"
                            success = True
                            break # ì„±ê³µí•˜ë©´ ì¬ì‹œë„ ë£¨í”„ íƒˆì¶œ
                        elif "SKIP" in chunk_text:
                            success = True # ë¬¸ì œê°€ ì—†ì–´ì„œ ë„˜ì–´ê°„ ê²ƒë„ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                            break
                            
                    except Exception as e:
                        # ì—ëŸ¬ ë‚˜ë©´ ì ì‹œ ì‰¬ì—ˆë‹¤ê°€ ì¬ì‹œë„
                        time.sleep(2)
                        continue
                
                if not success:
                    # 2ë²ˆ ì‹œë„í–ˆëŠ”ë°ë„ ì‹¤íŒ¨í•˜ë©´ ê²½ê³ ë§Œ ë„ìš°ê³  ë„˜ì–´ê° (ë©ˆì¶”ì§€ ì•ŠìŒ)
                    print(f"Failed to analyze {title} after retries.")
                
                total_progress.progress((i + 1) / len(batches))
                time.sleep(1) # API ê³¼ë¶€í•˜ ë°©ì§€

            st.session_state['full_analysis_result'] = full_accumulated_text
            status_text.success("âœ… ëª¨ë“  ë¬¸í•­ ë¶„ì„ ì™„ë£Œ! ì €ì¥í•˜ì„¸ìš”.")
            total_progress.empty()

        except Exception as e:
            st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if st.session_state['full_analysis_result']:
        st.divider()
        html_data = create_html_download(st.session_state['full_analysis_result'])
        st.download_button("ğŸ“¥ HTML íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", html_data, "ìˆ˜í•™_ì •ë°€_ë¶„ì„_ê²°ê³¼.html", "text/html")
