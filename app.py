import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold
import os
import tempfile
import time
import markdown
import pypdf  # í•„ìˆ˜: requirements.txtì— pypdf ì¶”ê°€
from dotenv import load_dotenv

# 1. ì„¤ì • ë° ë””ìì¸
st.set_page_config(page_title="ìˆ˜í•™ ê¸°ì¶œ ë¶„ì„ê¸° (Pro Only)", layout="wide")

st.markdown("""
    <style>
    div[data-testid="stMarkdownContainer"] p, 
    div[data-testid="stMarkdownContainer"] li, 
    div[data-testid="stMarkdownContainer"] td {
        font-size: 15px !important;
        line-height: 1.7 !important;
        font-family: 'Malgun Gothic', sans-serif !important;
    }
    thead tr th {
        background-color: #f0f2f6 !important;
        font-weight: bold !important;
        font-size: 16px !important;
        text-align: center !important;
        white-space: nowrap;
    }
    td { vertical-align: top !important; }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ’¯ ê³ ë“±í•™êµ ìˆ˜í•™ ê¸°ì¶œ vs ë¶€êµì¬ ë¶„ì„ê¸° (2.5 Pro ì „ìš©)")

# 2. API í‚¤ ì„¤ì • (ëª¨ë¸ ì„ íƒì°½ ì œê±° -> 2.5 Pro ê³ ì •)
with st.sidebar:
    st.header("ì„¤ì •")
    api_key = st.text_input("Google API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    
    st.divider()
    st.info("ğŸ”’ **ëª¨ë¸ ê³ ì •:** Gemini 2.5 Pro")
    st.info("â„¹ï¸ **ëŒ€ìš©ëŸ‰ ì§€ì›:** í° íŒŒì¼ì€ ìë™ìœ¼ë¡œ ë¶„í• í•˜ì—¬ 2.5 Proì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.")
    
    if api_key:
        os.environ["GOOGLE_API_KEY"] = api_key
        genai.configure(api_key=api_key)
        st.success("API í‚¤ í™•ì¸ ì™„ë£Œ!")
    else:
        st.warning("API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")

# 3. íŒŒì¼ ì—…ë¡œë“œ
col1, col2 = st.columns(2)
with col1:
    st.subheader("ğŸ“„ í•™êµ ê¸°ì¶œë¬¸ì œ PDF")
    exam_file = st.file_uploader("ê¸°ì¶œë¬¸ì œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'], key="exam")

with col2:
    st.subheader("ğŸ“˜ ë¶€êµì¬ PDF")
    textbook_file = st.file_uploader("ë¶€êµì¬ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'], key="text")


# --- ğŸ”¥ PDF ìë™ ë¶„í•  ë° ì—…ë¡œë“œ í•¨ìˆ˜ ---
def split_and_upload_pdf(uploaded_file, chunk_size_pages=30):
    """
    2.5 Proì˜ ì•ˆì •ì ì¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ PDFë¥¼ 30í˜ì´ì§€ì”© ì˜ë¼ì„œ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    """
    pdf_reader = pypdf.PdfReader(uploaded_file)
    total_pages = len(pdf_reader.pages)
    
    # í˜ì´ì§€ ìˆ˜ê°€ ì ìœ¼ë©´ ë¶„í•  ì—†ì´ ë°”ë¡œ ì—…ë¡œë“œ
    if total_pages <= chunk_size_pages:
        return [upload_single_file(uploaded_file)]

    status_text = st.empty()
    progress_bar = st.progress(0)
    status_text.info(f"ğŸ“š íŒŒì¼ì´ í½ë‹ˆë‹¤({total_pages}ìª½). 2.5 Proê°€ ì˜ ì½ì„ ìˆ˜ ìˆë„ë¡ {chunk_size_pages}ìª½ì”© ë‚˜ëˆ„ì–´ ì—…ë¡œë“œí•©ë‹ˆë‹¤...")
    
    uploaded_chunks = []
    
    for start_page in range(0, total_pages, chunk_size_pages):
        end_page = min(start_page + chunk_size_pages, total_pages)
        
        pdf_writer = pypdf.PdfWriter()
        for page_num in range(start_page, end_page):
            pdf_writer.add_page(pdf_reader.pages[page_num])
            
        # ë¶„í• ëœ PDF ì €ì¥ ë° ì—…ë¡œë“œ
        with tempfile.NamedTemporaryFile(delete=False, suffix=f"_part_{start_page}.pdf") as tmp:
            pdf_writer.write(tmp)
            tmp_path = tmp.name
            
        try:
            file_ref = genai.upload_file(tmp_path, mime_type="application/pdf")
            uploaded_chunks.append(file_ref)
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            progress = min((start_page + chunk_size_pages) / total_pages, 1.0)
            progress_bar.progress(progress)
            
        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
            
    status_text.success(f"âœ… {len(uploaded_chunks)}ê°œì˜ íŒŒíŠ¸ë¡œ ë¶„í•  ì™„ë£Œ! 2.5 Proì—ê²Œ ì „ë‹¬í•©ë‹ˆë‹¤.")
    time.sleep(1)
    status_text.empty()
    progress_bar.empty()
    
    return uploaded_chunks

def upload_single_file(uploaded_file):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
        tmp.write(uploaded_file.getvalue())
        tmp_path = tmp.name
    file_ref = genai.upload_file(tmp_path, mime_type="application/pdf")
    return file_ref

def wait_for_files_active(file_list):
    st.info("ğŸ“š AIê°€ íŒŒì¼ì„ ì½ê³  ìˆìŠµë‹ˆë‹¤...")
    for i, file_obj in enumerate(file_list):
        current_file = genai.get_file(file_obj.name)
        while current_file.state.name == "PROCESSING":
            time.sleep(2)
            current_file = genai.get_file(file_obj.name)
        
        if current_file.state.name == "FAILED":
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {current_file.uri}")
            st.stop()
            
    st.success("âœ… ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")

# HTML ë³€í™˜ í•¨ìˆ˜
def create_html_download(markdown_text):
    html_content = markdown.markdown(markdown_text, extensions=['tables'])
    styled_html = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="utf-8">
        <script>
        MathJax = {{ tex: {{ inlineMath: [['$', '$'], ['\\\\(', '\\\\)']], displayMath: [['$$', '$$'], ['\\\\[', '\\\\]']] }}, svg: {{ fontCache: 'global' }} }};
        </script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
        <style>
            body {{ font-family: 'Malgun Gothic', sans-serif; line-height: 1.6; padding: 40px; max-width: 1200px; margin: 0 auto; }}
            table {{ border-collapse: collapse; width: 100%; margin-bottom: 30px; }}
            th, td {{ border: 1px solid #ddd; padding: 15px; text-align: left; vertical-align: top; }}
            th {{ background-color: #007bff; color: white; text-align: center; white-space: nowrap; }}
            tr:nth-child(even) {{ background-color: #f2f2f2; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“Š ìˆ˜í•™ ê¸°ì¶œ vs ë¶€êµì¬ ì •ë°€ ë¶„ì„ ê²°ê³¼</h1>
        {html_content}
    </body>
    </html>
    """
    return styled_html

# 4. ë¶„ì„ ë¡œì§
if exam_file and textbook_file and api_key:
    if 'full_analysis_result' not in st.session_state:
        st.session_state['full_analysis_result'] = ""

    if st.button("ë¶„ì„ ì‹œì‘í•˜ê¸° ğŸš€", use_container_width=True):
        st.session_state['full_analysis_result'] = ""
        
        try:
            # 1. ê¸°ì¶œë¬¸ì œ ì—…ë¡œë“œ
            exam_ref = upload_single_file(exam_file)
            
            # 2. ë¶€êµì¬ ë¶„í•  ì—…ë¡œë“œ (30í˜ì´ì§€ì”©)
            textbook_refs = split_and_upload_pdf(textbook_file, chunk_size_pages=30)
            
            if not textbook_refs:
                st.stop()

            # 3. ëª¨ë“  íŒŒì¼ ëŒ€ê¸°
            all_files = [exam_ref] + textbook_refs
            wait_for_files_active(all_files)

            # 4. ëª¨ë¸ ì„¤ì • (ë¬´ì¡°ê±´ 2.5 Pro ì‚¬ìš©)
            model = genai.GenerativeModel(
                "gemini-2.5-pro",  # ì‚¬ìš©ì ìš”ì²­ëŒ€ë¡œ 2.5 Pro ê³ ì •
                generation_config={"temperature": 0.0, "max_output_tokens": 8192},
                safety_settings={
                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
                }
            )

            # 5. ë¶„ì„ ë°°ì¹˜ ì‹¤í–‰
            batches = [
                ("1ë²ˆ ~ 3ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 1ë²ˆë¶€í„° 3ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("4ë²ˆ ~ 6ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 4ë²ˆë¶€í„° 6ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("7ë²ˆ ~ 9ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 7ë²ˆë¶€í„° 9ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("10ë²ˆ ~ 12ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 10ë²ˆë¶€í„° 12ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("13ë²ˆ ~ 15ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 13ë²ˆë¶€í„° 15ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("16ë²ˆ ~ 18ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 16ë²ˆë¶€í„° 18ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("19ë²ˆ ~ 21ë²ˆ", "ê¸°ì¶œë¬¸ì œì˜ 19ë²ˆë¶€í„° 21ë²ˆ ë¬¸í•­ê¹Œì§€ë§Œ"),
                ("22ë²ˆ ~ ë§ˆì§€ë§‰", "ê¸°ì¶œë¬¸ì œì˜ 22ë²ˆë¶€í„° ì„œìˆ í˜• ëë²ˆ(ë§ˆì§€ë§‰) ë¬¸í•­ê¹Œì§€")
            ]

            full_accumulated_text = ""
            status_text = st.empty()

            for i, (title, range_desc) in enumerate(batches):
                status_text.info(f"ğŸ”„ {title} ë¶„ì„ ì¤‘... ({i+1}/{len(batches)})")
                
                if i > 0: st.markdown("---")
                st.markdown(f"### ğŸ“‹ {title}")
                full_accumulated_text += f"\n\n### ğŸ“‹ {title}\n\n"
                placeholder = st.empty()
                
                # í”„ë¡¬í”„íŠ¸: ë¶„í• ëœ ë¶€êµì¬ë¥¼ í•˜ë‚˜ë¡œ ì¸ì‹í•˜ë¼ê³  ì§€ì‹œ
                prompt = f"""
                ë‹¹ì‹ ì€ ìˆ˜í•™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                ì²« ë²ˆì§¸ PDFëŠ” 'ê¸°ì¶œë¬¸ì œ'ì´ê³ , ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤ì€ 'ë¶€êµì¬'ë¥¼ ë¶„í• í•˜ì—¬ ì—…ë¡œë“œí•œ ê²ƒì…ë‹ˆë‹¤.
                ë‚˜ë¨¸ì§€ íŒŒì¼ë“¤ì„ **ëª¨ë‘ í•©ì³ì„œ í•˜ë‚˜ì˜ ë¶€êµì¬**ë¡œ ì¸ì‹í•˜ê³  ë¶„ì„í•˜ì„¸ìš”.
                
                ë‘ ìë£Œë¥¼ ë¹„êµí•˜ì—¬ **{range_desc}** ìƒì„¸ ë¶„ì„í•˜ì„¸ìš”.
                
                **[ì¶œë ¥ ì„œì‹ ê°€ì´ë“œë¼ì¸ - ì—„ê²© ì¤€ìˆ˜]**
                1. **ë¶€êµì¬ ë¬¸í•­ í‘œê¸°:** - ì²« ì¤„: **`p.í˜ì´ì§€ë²ˆí˜¸ ë¬¸í•­ë²ˆí˜¸`** (ì˜ˆ: p.80 285ë²ˆ)
                   - ë‘ ë²ˆì§¸ ì¤„ë¶€í„°: **[ì›ë³¸]** íƒœê·¸ ì•„ë˜ì— **ë¶€êµì¬ ë¬¸ì œ ì›ë¬¸ì„ ë°˜ë“œì‹œ í…ìŠ¤íŠ¸ë¡œ ì ìœ¼ì„¸ìš”.**
                
                2. **ë³€í˜• í¬ì¸íŠ¸ í‘œê¸°:** - ë°˜ë“œì‹œ **ê¸€ë¨¸ë¦¬ ê¸°í˜¸(â€¢)**ë¥¼ ì‚¬ìš©í•˜ê³ , í‚¤ì›Œë“œëŠ” êµµê²Œ ì²˜ë¦¬í•˜ì„¸ìš”.
                
                **[í•„ìˆ˜ í…Œì´ë¸” ì–‘ì‹]**
                **ë°˜ë“œì‹œ í‘œ ì•ì— ë¹ˆ ì¤„ì„ í•˜ë‚˜ ë„ìš°ê³  í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”.**
                
                | ë¬¸í•­ | ê¸°ì¶œë¬¸ì œ ìš”ì•½ | ë¶€êµì¬ ìœ ì‚¬ ë¬¸í•­ | ìƒì„¸ ë³€í˜• ë¶„ì„ |
                | :--- | :--- | :--- | :--- |
                | (ë²ˆí˜¸) | **[ì›ë³¸]**<br>(ê¸°ì¶œ ë¬¸ì œ í…ìŠ¤íŠ¸)<br><br>**[ìš”ì•½]**<br>(í•µì‹¬ ìš”ì•½) | **[ì›ë³¸]**<br>p.00 000ë²ˆ<br>(ë¶€êµì¬ ë¬¸ì œ ì›ë¬¸ í…ìŠ¤íŠ¸ í•„ìˆ˜ ê¸°ì¬)<br><br>**[ìš”ì•½]**<br>(ë‚´ìš© ìš”ì•½) | **â–¶ ë³€í˜• í¬ì¸íŠ¸**<br>â€¢ **í‚¤ì›Œë“œ**: ì„¤ëª…<br>â€¢ **í‚¤ì›Œë“œ**: ì„¤ëª…<br><br>**â–¶ ì¶œì œ ì˜ë„**<br>(í‰ê°€ ëª©í‘œ) |
                """
                
                # ğŸ”¥ [í•µì‹¬] 2.5 Proì—ê²Œ ëª¨ë“  íŒŒì¼ ì¡°ê°ì„ ë‹¤ ë˜ì ¸ì¤Œ
                request_content = [prompt, exam_ref] + textbook_refs
                
                chunk_text = ""
                try:
                    stream = model.generate_content(request_content, stream=True)
                    for chunk in stream:
                        if chunk.text:
                            chunk_text += chunk.text
                            placeholder.markdown(chunk_text, unsafe_allow_html=True)
                except Exception as e:
                    # 400 ì—ëŸ¬ ì²˜ë¦¬ (2.5 Pro ìš©ëŸ‰ ì´ˆê³¼ ì‹œ)
                    if "400" in str(e):
                        st.error("ğŸš¨ 2.5 Pro ëª¨ë¸ì˜ ì²˜ë¦¬ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤.")
                        st.warning("ë¶„ì„ ë²”ìœ„ë¥¼ ë” ì¢íˆê±°ë‚˜(ì˜ˆ: 2ë¬¸ì œì”©), ë¶€êµì¬ íŒŒì¼ì˜ í˜ì´ì§€ë¥¼ ì¡°ê¸ˆ ë” ì¤„ì—¬ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        st.stop()
                    else:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                
                full_accumulated_text += chunk_text + "\n\n"

            st.session_state['full_analysis_result'] = full_accumulated_text
            status_text.success("âœ… ë¶„ì„ ì™„ë£Œ! ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")

        except Exception as e:
            st.error(f"ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    if st.session_state['full_analysis_result']:
        st.divider()
        html_data = create_html_download(st.session_state['full_analysis_result'])
        st.download_button("ğŸ“¥ HTML íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ", html_data, "ìˆ˜í•™_ê¸°ì¶œ_ë¶„ì„_ê²°ê³¼.html", "text/html")
